---
id: 061e96ef-5be4-4eb5-9cbe-d8a1c5ab9a4e
title: Andrew_Ng
desc: ''
updated: 1621274000831
created: 1617555740665
---

# Introduction

## Machine Learning definition

> a computer program is said to learn from experience `E` with respect to some task `T` and some performance measure `P`, if its performance on T, as measured by P, improves with experience E
>
>Tom Mitchell (1998)

ä¸‹è±¡æ£‹ï¼š
+ (T) ä»»åŠ¡ï¼šä¸‹è±¡æ£‹
+ (E) ç»éªŒ: ä¸‹å‡ ä¸‡éè±¡æ£‹çš„ç´¯ç§¯
+ (P) æ€§èƒ½æŒ‡æ ‡ï¼šä¸‹ä¸€ç›˜æ£‹çš„æˆåŠŸæ¦‚ç‡

æ ‡è®°åƒåœ¾é‚®ä»¶ï¼š
+ T: æ ‡è®°åƒåœ¾é‚®ä»¶çš„è¡Œä¸º
+ Eï¼šè§‚å¯Ÿä½ æ ‡è®°åƒåœ¾è¡Œä¸ºçš„å†å²
+ Pï¼šæ­£ç¡®æ ‡è®°åƒåœ¾é‚®ä»¶çš„æ¯”ä¾‹

### Machine Learning algorithmsï¼š

+ Supervised learning
+ Unsupervised learning
+ Reinforcement learning
+ recommender systems

## Supervised Learning
`right answers` givenï¼Œthe task is to produce more these `right answers`  
In supervised learning, we are given a data set and already know **what our correct output should look like**, having the idea that there is a relationship between the input and the output.

### Regression Problem
Predict continuous valued output, meaning that we are trying to map input variables to some continuous function.

>e.g. Given data about the size of houses on the real estate market, try to predict their price. Price as a function of size is a continuous output
>e.g.  Given a picture of a person, we have to predict their age on the basis of the given picture

### Classification Problem
we are trying to map input variables into discrete categories. æ ¹æ®ç»™å®šçš„æ•°æ®é›†ï¼Œåˆ¤æ–­ä¸€ä¸ªæ•°æ®åº”è¯¥å½’å±äºå“ªä¸ªç±»åˆ«ï¼Œ

>e.g. from the last house price example, we making our output about whether the house "sells for more or less than the asking price.
>e.g.  Given a patient with a tumor, we have to predict whether the tumor is malignant or benign. (å›¾ä¸­å±•ç¤ºäº†å¹´é¾„å’Œè‚¿ç˜¤å¤§å°ï¼Œå®é™…ä¸­å¯èƒ½æœ‰æ›´å¤šï¼Œç”šè‡³æ— é™å¤šçš„æŒ‡æ ‡)
![](/assets/images/2021-04-05-01-36-54.png)

## Unsupervised Learning

Unsupervised learning allows us to approach problems with little or no idea what our results should look like. We can derive structure from data where we don't necessarily know the effect of the variables.

We can derive this structure by clustering the data based on relationships among the variables in the data.

With unsupervised learning there is no feedback based on the prediction results.

### Clustering
>e.g. Take a collection of 1,000,000 different genes, and find a way to automatically group these genes into groups that are somehow similar or related by different variables, such as lifespan, location, roles, and so on.

### Non-clustering
>e.g. The "Cocktail Party Algorithm", allows you to find structure in a chaotic environment. (i.e. identifying individual voices and music from a mesh of sounds at a cocktail party).

# One variable Linear regression

## Model representation and Cost function

**Hypothesis**: $h_\theta(x) = \theta_0 + \theta_1x$
**Parameters**: $\theta_0, \theta_1$
**Cost Function**: $J(\theta_0, \theta_1) = \frac{1}{2m}\sum_{i=1}^m(\hat{y}_i-y_i)^2 = \frac{1}{2m}\sum_{i=1}^m(h_\theta(x_i)-y_i)^2$
**Goal**: $\underset{\theta_0, \theta_1}{\rm minimize}J(\theta_0, \theta_1)$

+ m: the size of traning datasetï¼Œæ¯”å¦‚889æ¡
+ 1/m: æ˜¯ä¸ºäº†æ±‚å¹³å‡æ•°
+ 1/2: æ˜¯ä¸ºäº†åœ¨äºŒé¡¹å¼æ±‚å¯¼æ—¶èƒ½æ¶ˆæ‰

This function is otherwise called the `Squared error function`, or `Mean squared error`. (æœ€å°äºŒä¹˜æ³•) 

## Gradient descent algorithm

å³æ¢¯åº¦ä¸‹é™æ³•

repeat until convergence {   
    $\quad\theta_j := \theta_j - \alpha\frac{\partial}{\partial\theta_j}J(\theta_0, \theta_1)\quad(\rm simultaneously\ update\ j=0\ and\ j=1)$
}

>the derivative of a scalar valued multi-variable function always means the direction of the steepest `ascent`, so if we want to go `desent` direction, we `minus` the derivative.

plug in the $h_\theta(x)$ and $J(\theta_0, \theta_1)$, we got
$$
\begin{cases}
    \theta_0 := \theta_0-\alpha\frac{\partial}{\partial\theta_0}\frac{1}{2m}\sum_{i=1}^m(h_\theta(x_i)-y_i)^2 \\
    \theta_1 := \theta_1-\alpha\frac{\partial}{\partial\theta_1}\frac{1}{2m}\sum_{i=1}^m(h_\theta(x_i)-y_i)^2
\end{cases}
\Rightarrow
\begin{cases}
    \theta_0 := \theta_0-\alpha\frac{1}{m}\sum_{i=1}^m(h_\theta(x_i)-y_i) \\
    \theta_1 := \theta_1-\alpha\frac{1}{m}\sum_{i=1}^m(h_\theta(x_i)-y_i) \cdot x_i
\end{cases}
$$
the partial derivative of $\theta_1$ use chain rule apparently.
>the `cost function` for linear regression is always going to be a bow shaped function called `Convex function`, so this function doesn't have any local uptimum but one global uptimum.

### Batch Gradient Descent

we also call this algorithm `Batch Gradient Descent`, **batch** means each step of gradient descent uses all the training examples. 

## Multivariate Linear Regression

### Multiple Features

å¦‚æœå¤šäº†å‡ ä¸ªå‚æ•°ï¼š

size | rooms | flats | ages | price
-----|-------|-------|------|----
127.3 | 8 | 2 | 15 | 235,72
89.5 | 3 | 1 | 8 | 17,345
... |

Linear regression with multiple variables is also known as "**multivariate linear regression**". The multivariable form of the hypothesis function accommodating these multiple features is as follows:

$h_\theta(x)=\theta_0+\theta_1x_1+\theta_2x_2+\theta_3x_3+\cdots+\theta_nx_n$

ä¸ºäº†å†™æˆçŸ©é˜µå½¢å¼ï¼Œæˆ‘ä»¬è¡¥ä¸€ä¸ª$x_0=1$ï¼Œåˆ™
$h_\theta(x)=[\theta_0\ \theta_1\ \cdots\ \theta_n]\cdot
\begin{bmatrix}
x_0\\
x_1\\
\vdots
x_n
\end{bmatrix}
= \theta^T \cdot x
$
while the *cost function* as:
$J(\theta) = \frac{1}{2m}\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})^2$
> è¿™é‡Œç”¨äº†$x^{(i)}$è€Œä¸æ˜¯$x_i$ï¼Œæ˜¯ä¸ºäº†æ›´ä¸¥è°¨ï¼Œå³ä¸Šè§’è¡¨ç¤ºç¬¬å‡ ç»„è®­ç»ƒæ•°æ®ï¼Œå³ä¸‹è§’ç”¨æ¥è¡¨ç¤ºç¬¬å‡ ä¸ªfeature, å³$x^{(3)}_4$

the gradient descent:
Repeat {
    $\quad\theta_j:=\theta_j-\alpha\frac{\partial}{\partial\theta_j}J(\theta)\;(\small\rm simultaneously\ update\ for\ every\ j=0,\dots,n)$
}
plug the $J(\theta)$ in:

$\theta_j:=\theta_j-\alpha\frac{1}{m}\sum_{i=1}^{m}(h_\theta(x^{(i)})-y^{(i)})\cdot x^{(i)}_j$

å…¶ä¸­$x^{(i)}_j$å°±æ˜¯$\theta_j \cdot x^{(i)}_j$å¯¹$\theta_j$æ±‚çš„å¯¼æ•°ã€‚

### Feature Scaling

Get every feature into approximately a $-1\leq x_i \leq 1$ range (to make sure features are on a similar scale).

### Mean Normalization

Replace $x_i$ with $x_i-u_i$ to make features have approximately zero mean (Do not apply to $x_0$, because it's always be 1):
$x_i=\frac{x_i-u_i}{s_i}$ 
$u_i$: the `average` of $x_i$ in training set
$s_i$: the `range` of $x_i$, aka: max-min, OR, the `standard deviation`
å¦‚æœsizeå¹³å‡åœ¨1000feetså·¦å³ï¼Œæ•°æ®é›†çš„è·¨åº¦åœ¨2000ï¼Œé‚£ä¹ˆå¯ä»¥è®¾$x_1=\frac{size-1000}{2000}$ï¼Œè¿™æ ·$x_i$å°±è½åœ¨äº†$-0.5\leq x_i \leq 0.5$

### debuging Learing rate

`debuging` making sure gradient descent is working correctly. $J(\theta)$ should decrease after every iteration (for a sufficiently small $\alpha$).
æ¯”å¦‚ä½ å‘ç°æ›²çº¿å‘ä¸Šäº†ï¼Œå¯èƒ½æ˜¯é€‰æ‹©äº†ä¸æ°å½“ï¼ˆè¿‡å¤§ï¼‰çš„learning rateï¼ˆ$\alpha$ï¼‰ï¼Œè€Œå¦‚æœæ”¶æ•›å¾—å¤ªæ…¢äº†ï¼Œé‚£å¯èƒ½æ˜¯é€‰æ‹©äº†ä¸€ä¸ªå¤ªå°çš„learning rateã€‚
![](/assets/images/2021-04-08-14-32-52.png)

### Features and polynomial regression

We can improve our features and the form of our hypothesis function in a couple different ways.
We can combine multiple features into one. For example, we can combine $x_1$ and $x_2$ into a new feature $x_3$ by taking $x_1\cdot x_2$,(æ¯”å¦‚æˆ¿é—´çš„è¿›æ·±å’Œå®½åº¦å˜æˆæˆ¿å­çš„é¢ç§¯)

Our hypothesis function `need not be linear` (a straight line) if that does not fit the data well.
We can change the behavior or curve of our hypothesis function by making it a quadratic, cubic or square root function (or any other form). (ä¼šå½¢æˆæŠ›ç‰©çº¿$-x^2$ï¼Œä¸Šå‡æ›²çº¿($x^3, \sqrt2$)ç­‰ç­‰)

For example, if our hypothesis function is $h_\theta(x)=\theta_0+\theta_1x_1$ then we can create additional features based on $x_1$, to get the quadratic function $h_\theta(x)=\theta_0+\theta_1x_1+\theta_2x_1^2$ or qubic function $h_\theta(x)=\theta_0+\theta_1x_1+\theta_2x_1^2+\theta_3x_1^3$

we just need to set $x_2=x^2_1$ and $x_3=x_1^3$
and, the range will be significantly change, you should right normalization your data (feature scaling).

## Computing Parameters Analytically

### Normal equations method

é™¤äº†æ¢¯åº¦ä¸‹é™ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥ç”¨Normal equationæ¥æ±‚æå€¼ï¼Œ
 a Method to solve for $\theta$ analyticallyã€‚
 
 ç®€åŒ–åˆ°ä¸€ä¸ªæ™®é€šçš„æŠ›ç‰©çº¿ï¼Œæˆ‘ä»¬çŸ¥é“å…¶æå€¼æ˜¾ç„¶å°±æ˜¯å…¶å¯¼æ•°ä¸º0çš„åœ°æ–¹ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥ç”¨æ±‚$\frac{d}{d\theta}h_\theta(x)=0$ï¼Œåœ¨å¤šé¡¹å¼é‡Œï¼Œæˆ‘ä»¬è¡¥é½$x_0=1$çš„ä¸€åˆ—ä¸ºå‚æ•°çŸ©é˜µ$X$ï¼Œ$\theta$å–å¦‚ä¸‹å€¼æ˜¯æœ‰æœ€å°å€¼ï¼š
$\theta=(X^TX)^{-1}X^Ty$

and There's **no need** to do feature scaling with the normal equation

Gradient Descent | Normal Equation
-----------------|----------------
Need to choose alpha | No need to choose alpha
Needs many iterations | No need to iterate
$O(kn^2)$ | $O(n^3)$ need to calculate inverse of X^TXX 
Works well when n is large | Slow if n is very large

### Noraml Equation Noninvertibility

in octave, we can use `pinv` rather `inv`. the `pinv` function will give you a value of $\theta$ even if $X^TX$ is not invertible. the `p` means `pseudo`.

It's common causes by:

- Redundant features, where two features are very closely related (i.e. they are linearly dependent)
- Too many features (e.g. m â‰¤ n). In this case, delete some features or use "regularization" (to be explained in a later lesson).

# Logistic Regression

## Classfication and Representation

For now, we will focus on the binary classification problem in which y can take on only two values, 0 and 1 $\Rightarrow \ y\in\{0,1\}$.

To attempt classification, one method is to use linear regression and map all predictions greater than 0.5 as a 1 and all less than 0.5 as a 0. However, this method doesn't work well because classification is not actually a linear function.

æ¯”å¦‚æŠŠ0.8æ˜ å°„æˆ1æ˜¯åˆç†çš„ï¼Œä½†800å‘¢ï¼Ÿ 
$h_\theta$å¯èƒ½è¿œå¤§äº1æˆ–è¿œå°äº0ï¼Œåœ¨æ˜çŸ¥ç›®æ ‡é0å³1çš„æƒ…å†µä¸‹ï¼Œè¿™æ˜¯ä¸åˆç†çš„ï¼Œç”±æ­¤å¼•å…¥äº†$0 \leq h_\theta \leq 1$çš„`Logistic Regression`ï¼ˆå…¶å®æ˜¯ä¸€ä¸ªclassification algorithm)ã€‚

## Hypothesis Representation

çº¿æ€§å›å½’çš„($\theta^Tx$)å¹¶ä¸èƒ½å¾ˆå¥½åœ°ç”¨æ¥è¡¨ç¤ºclassification problemï¼Œä½†æˆ‘ä»¬å¯ä»¥åŸºäºå…¶æ¥é€‰æ‹©ä¸€ä¸ªå‡½æ•°(g)ï¼Œè®©å®ƒçš„è¾“å‡ºå€¼åœ¨(0,1)ä¹‹é—´ï¼Œè¿™ä¸ªå‡½æ•°å«`Sigmoid Function`æˆ–`Logistic Function`:

$h_\theta(x) = g(\theta^Tx)$  
$z = \theta^Tx$  
$g(z) = \frac{1}{1+e^{-z}}$

`Sigmoid`å°±å«Så‹å‡½æ•°ï¼Œå› ä¸ºå®ƒçš„å›¾åƒæ˜¯è¿™æ ·çš„ï¼š
![](/assets/images/2021-04-27-01-20-49.png)
The function g(z), shown here, **maps any real number** to the (0, 1) interval, making it useful for transforming an arbitrary-valued function into a function better suited for classification.

æ­£ç¡®ç†è§£`Sigmoid`å‡½æ•°ï¼Œå®ƒè¡¨ç¤ºçš„æ˜¯åœ¨ç»™å®šçš„ï¼ˆåŸºäº$\theta$å‚æ•°çš„ï¼‰xçš„å€¼çš„æƒ…å†µä¸‹ï¼Œè¾“å‡ºä¸º1çš„**æ¦‚ç‡**ã€‚

$h_\theta(x) = P(y = 1\ |\ x;\theta)$

æ˜¾ç„¶ï¼Œy=1ä¸y=0çš„æ¦‚ç‡æ˜¯äº’è¡¥çš„ã€‚

## Decision boundary

ä»ä¸ŠèŠ‚çš„å‡½æ•°å›¾åƒå¯çŸ¥ï¼Œ$z=0$å°±æ˜¯0.5çš„åˆ†ç•Œç‚¹ï¼Œè€Œ$z = \theta^Tx$å°±æ˜¯$g(z)$çš„å…¥å‚ï¼š
$
\begin{cases}
h_\theta(x) \geq 0.5 \rightarrow y=1 \\
h_\theta(x) \lt 0.5 \rightarrow y=0
\end{cases}
\Rightarrow
g(z) \geq 0.5\ when\ z \geq 0 \Rightarrow \theta^Tx \geq 0 
$

åŒæ—¶ï¼Œ$g(z) = \frac{1}{1+e^{-z}}$å¾—çŸ¥zè¶‹è¿‘æ— ç©·å¤§ï¼Œg(x)è¶Šè¶‹è¿‘1ï¼Œåä¹‹è¶Šè¶‹è¿‘0ï¼Œæ„å‘³ç€**è¶Šå¤§çš„zå€¼**è¶Šå€¾å‘äºå¾—åˆ°`y = 1`çš„ç»“è®ºã€‚

The `decision boundary` is the line that separates the area where y = 0 and where y = 1. It is created by our hypothesis function. åŸºæœ¬ä¸Šï¼Œå®ƒå°±æ˜¯ç”±$\theta^Tx=0$ç¡®ç«‹çš„ã€‚

> è®°ä½ï¼Œ$\theta_i$çš„å€¼éƒ½æ˜¯ä¼°è®¡å€¼ï¼Œæ­£ç¡®åœ°é€‰æ‹©ï¼ˆæˆ–ä¸åŒåœ°é€‰æ‹©ï¼‰$\theta$ä¼šå¯¼è‡´ä¸åŒçš„`dicision boundary`ï¼Œé€‰æ‹©ä¹Ÿæ˜¯å……æ»¡æŠ€å·§çš„ã€‚

ä¾‹: å¯¹äº$h_\theta(x) = g(\theta_0 + \theta_1x_1 + \theta_2x_2)$ï¼Œå¦‚æœå–:
$\begin{aligned}
& \theta = \begin{bmatrix}5\\-1\\0\end{bmatrix} \\
& y = 1\ {\color{red}if}\ 5 + (-1)x_1 + 0x_2 \geq 0 \\
& \Rightarrow x_1 \leq 5
\end{aligned}$

è€Œé€‰$[-3, 1, 1]^T$ï¼Œåˆ™æœ‰$x_1+x_2=3$

è¿™å°†æ˜¯ä¸¤æ¡ä¸åŒçš„ç›´çº¿ï¼Œå³ä¸åŒçš„`dicision boundary`

æ›´å¤æ‚çš„ä¾‹å­ï¼š$h_\theta(x) = g(\theta_0+\theta_1x_1+\theta_2x_2+\theta_3x_1^2+\theta_4x_2^2)$ï¼Œå·§å¦™åœ°è®¾$\theta = [-1, 0, 0, 1, 1]$ï¼Œå°†ä¼šå¾—åˆ°$x_1^2 + x_2^2 = 1$ï¼Œè¿™å°±æ˜¯ä¸€ä¸ªåœ†å˜›ã€‚

> Again, the `decision boundary` is a property, not of the traning set, but of the hypothesis under the parameters. (ä¸åŒçš„$\theta$ç»„åˆï¼Œç»™å‡ºä¸åŒçš„decision boundary)

## Cost function

$J(\theta)=\frac{1}{m}\sum_{i=1}^{m}Cost(h_\theta x^{(i)},y^{(i)})$

$Cost(h_\theta(x), y) =\begin{cases}
    -log(h_\theta(x)) & if\ y=1 \\
    -log(1-h_\theta(x)) & if\ y=0
\end{cases}$

å¼•å…¥logæ˜¯ä¸ºäº†å½¢æˆå‡¸å‡½æ•°ï¼ˆconvexï¼‰ï¼Œ`-log(z)`ä¸`-log(1-z)`çš„å‡½æ•°å›¾å½¢åˆ†åˆ«å¦‚ä¸‹ï¼Œå–(0,1)éƒ¨åˆ†ï¼š
![](/assets/images/2021-04-27-14-08-06.png)
![](/assets/images/2021-04-27-14-08-14.png)

>æ³¨æ„ï¼š$z=h_\theta(x)$

ä»å›¾åƒåˆ†æï¼Œæˆ‘ä»¬èƒ½å¾—åˆ°å¦‚ä¸‹ç»“è®ºï¼š

- å½“`y = 0`æ—¶ï¼Œå¦‚æœ $h_\theta x = 0$ï¼ˆè¯­ä¹‰ä¸ºy=1çš„æ¦‚ç‡ä¸º0ï¼‰ï¼Œcost functionä¹Ÿä¸º0ï¼Œå³é¢„æµ‹å¾ˆç²¾ç¡®ï¼Œè¯­ä¹‰ä¸Šä¹Ÿæ˜¯ç›¸åŒçš„ï¼Œy=0æ—¶y=1çš„æ¦‚ç‡å½“ç„¶æ˜¯0
- å½“`y = 0`æ—¶ï¼Œå¦‚æœ $h_\theta x = 1$ï¼ˆè¯­ä¹‰ä¸ºy=1çš„æ¦‚ç‡ä¸º100%ï¼‰ï¼Œcost functionä¹Ÿä¸ºæ— ç©·å¤§ï¼Œå³è¯¯å·®æ— é™å¤§ï¼Œè¯­ä¹‰ä¸Šï¼Œy=0å½“ç„¶ä¸èƒ½ä¸y=1å¹¶å­˜

## Simplified cost function and gradient descent

### Simplify Cost function
ä¸ŠèŠ‚ä¸¤ä¸ªç­‰å¼å¯ä»¥ç®€åŒ–ä¸ºï¼š

$Cost(h_\theta(x),y) = -ylog(h_\theta(x)) - (1-y)log((1-h_\theta(x^{(i)})))$

å¾ˆå¥½ç†è§£ï¼Œyåªèƒ½ä¸º0æˆ–1ï¼Œyå’Œ(1-y)å¿…æœ‰ä¸€ä¸ªæ˜¯0ï¼Œæ‰€ä»¥ï¼š

$\begin{aligned}
J(\theta) & = \frac{1}{m}\sum_{i=1}^mCost(h_\theta(x),y) \\
          & = -\frac{1}{m}\sum_{i=1}^m[
    y^{(i)}log(h_\theta(x^{(i)})) + (1-y^{(i)})log(1-h_\theta(x^{(i)}))
]\end{aligned}$
> from `the principle of maximum likelihood estimation`(æœ€å¤§ä¼¼ç„¶ä¼°è®¡)

for $\underset{m}{min}J(\theta)$ get the $\theta$ï¼Œ the output: $h_\theta(x) = \frac{1}{1+e^{-\theta^Tx}}$ï¼Œæ„æ€æ˜¯ç»™å®šxèƒ½å¾—åˆ°$p(y=1 | x;\theta)$ï¼Œå³y=1çš„æ¦‚ç‡ï¼Œå³å®Œæˆäº†clasificationã€‚

A vectorized implementation is:

$h=g(X\theta)$

$J(\theta) = -\frac{1}{m}\cdot(-y^Tlog(h)-(1-y)^Tlog(1-h))$ ï¼ˆäº¤å‰ç†µæŸå¤±`Binary Cross Entropy Loss`ï¼‰

### Gradient Descent

$\theta_j:=\theta_j - \alpha\frac{\partial}{\partial\theta_j}J(\theta) \Rightarrow \theta_j:=\theta_j - \frac{\alpha}{m}\sum_{i=i}^{m}(h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)}$

Looks identical to `linear regression`
- for `linear regression`, $h_\theta(x) = \theta^Tx$
- for `logistical regression`, $h_\theta(x) = \frac{1}{1+e^{-\theta^Tx}}$
- çº¿æ€§å›å½’é‡Œ$\theta^Tx$ä¸yç›¸å‡å°±æ˜¯æŸå¤±å‡½æ•°ï¼Œé€»è¾‘å›å½’é‡Œï¼Œ$\theta^Tx$è¦ä»£å…¥åˆ°ä¸Šè¿°logå‡½æ•°é‡Œæ‰æ˜¯æŸå¤±å‡½æ•°!!!

> è¿™é‡Œä¸ºä»€ä¹ˆæŸå¤±å‡½æ•°åˆ†æ˜ä¸æ˜¯$h_\theta(x) - y$æ±‚å¯¼åä»ç„¶å˜æˆè¿™ä¸ªå½¢å¼äº†å‘¢ï¼Ÿä¸‹é¢æˆªå›¾æœ‰æ±‚å¯¼è¿‡ç¨‹ï¼Œå¯è§å®ƒåªæ˜¯**æ°å¥½**æ˜¯è¿™ä¸ªå½¢æ€ï¼Œä½†æ˜¯**åƒä¸‡ä¸è¦**è®¤ä¸ºè¿™æ‰æ˜¯æ¨å¯¼ä¾æ®ï¼Œè¿™å°±æ˜¯æ•°å­¦ä¹‹ç¾å§ã€‚

æ±‚å¯¼è¿‡ç¨‹ï¼š
![](/assets/images/2021-04-27-23-35-14.png)

ä»¥åå†è‡ªå·±è¯•è‡ªå·±æŒ‰è¡Œæ±‚å¯¼å†æ±‚å’Œï¼Œå¯¹äºçŸ©é˜µï¼Œè¿˜æ˜¯ç”¨çŸ©é˜µæ±‚å¯¼çš„é“¾å¼æ³•åˆ™ï¼š
$z = f(Y),\ Y = AX+B \Rightarrow 
\frac{\partial z}{\partial X} = A^T\frac{\partial z}{\partial Y}$
å³å…ˆå¯¹å››åˆ™è¿ç®—è¿›è¡Œæ±‚å¯¼ï¼Œç„¶åå†æ ¹æ®çŸ©é˜µåœ¨xå·¦è¾¹è¿˜æ˜¯å³è¾¹æ¥å·¦ä¹˜æˆ–å³ä¹˜$A^T$
[reference](https://www.cnblogs.com/pinard/p/10825264.html)

æ‰€ä»¥ï¼š
$\theta := \theta - \frac{\alpha}{m}X^T(g(X\theta) - \vec{y})$

> è§£é‡Šï¼š
1. cost functionæ˜¯é‚£ä¸€ä¸²logç›¸å‡ï¼Œæœ€å¤–å±‚æ±‚å¯¼åå°±æ˜¯$h(x)-y$
2. è€Œ$h(x) = g(X\theta)$ï¼Œåº”ç”¨é“¾å¼æ³•ï¼Œå†…å±‚å°±æ˜¯$X\theta$å¯¹$\theta$ç»§ç»­æ±‚å¯¼ï¼Œç»“æœæ˜¯æŠŠ$X^T$ä¹˜åˆ°å·¦è¾¹å»

ç›´æ¥ç”¨emojiå­—ç¬¦æŠŠğœƒå†™åˆ°æ–¹æ³•åé‡Œå»ï¼Œç›´æ¥è¿˜åŸå…¬å¼ï¼Œå¦‚æœæœ‰å¯¹è€å¸ˆä»£ç ä¸å…¬å¼çš„å¯¹ç…§äº§ç”Ÿç–‘æƒ‘çš„ï¼Œçœ‹çœ‹æœ‰æ²¡æœ‰æ›´ç›´è§‚


## Advanced optimization

`Conjugate gradient`ï¼ˆå…±è½­æ¢¯åº¦ï¼‰, `BFGS`ï¼ˆå±€éƒ¨ä¼˜åŒ–æ³•, Broyden Fletcher Goldfarb Shannï¼‰, and `L-BFGS`ï¼ˆæœ‰é™å†…å­˜å±€éƒ¨ä¼˜åŒ–æ³•ï¼‰ are more sophisticated, faster ways to optimize Î¸ that can be used instead of gradient descent. 
è¿™äº›ç®—æ³•æœ‰ä¸€ä¸ªæ™ºèƒ½çš„å†…éƒ¨å¾ªç¯ï¼Œç§°ä¸ºçº¿æ€§æœç´¢(line search)ç®—æ³•ï¼Œå®ƒå¯ä»¥è‡ªåŠ¨å°è¯•ä¸åŒçš„å­¦ä¹ é€Ÿç‡ ã€‚åªéœ€è¦ç»™è¿™äº›ç®—æ³•æä¾›è®¡ç®—å¯¼æ•°é¡¹å’Œä»£ä»·å‡½æ•°çš„æ–¹æ³•ï¼Œå°±å¯ä»¥è¿”å›ç»“æœã€‚é€‚ç”¨äºå¤§å‹æœºå™¨å­¦ä¹ é—®é¢˜ã€‚

We first need to provide a function that evaluates the following two functions for a given input value Î¸:

$\begin{aligned}
&J(\theta) \\
&\frac{\partial}{\partial\theta_j}J(\theta)
\end{aligned}$

then wirte a single function that returns both of these:

```
function [jVal, gradient] = costFunction(theta)
  jVal = [...code to compute J(theta)...];
  gradient = [...code to compute derivative of J(theta)...];
end
```

Then we can use octave's `fminunc()` optimization algorithm along with the `optimset()` function that creates an object containing the options we want to send to "fminunc()". 

```
options = optimset('GradObj', 'on', 'MaxIter', 100);
initialTheta = zeros(2,1);
   [optTheta, functionVal, exitFlag] = fminunc(@costFunction, initialTheta, options);
```

## Multi-class classfication: One-vs-all

One-vs-all -> One-vs-restï¼Œæ¯ä¸€æ¬¡æŠŠæ„Ÿå…´è¶£çš„æŒ‡æ ‡è®¾ä¸º1ï¼Œå…¶å®ƒåˆ†ç±»ä¸º0ï¼Œå…¶å®ƒæŒ‡æ ‡äº¦ç„¶ï¼Œä¹Ÿå°±æ˜¯è¯´å¯¹æ¯ä¸€æ¬¡åˆ†ç±»ï¼Œéƒ½æ˜¯ä¸€æ¬¡binaryçš„åˆ†ç±»ã€‚

$h_\theta^{(i)}(x) = P(y=i\ |\ x;\theta)\quad(i=1,2,3...)$ è¿™æ ·å°±å¾—åˆ°äº†iä¸º1ï¼Œ2ï¼Œ3ç­‰æ—¶çš„æ¦‚ç‡ï¼Œæ¦‚ç‡æœ€å¤§çš„å³ä¸ºæœ€æ¥è¿‘çš„hypothesisã€‚

# Regularization

## The problem of overfitting

å¦‚æœæ ·æœ¬ç¦»å›å½’æ›²çº¿ï¼ˆæˆ–ç›´çº¿ï¼‰åå·®è¾ƒå¤§ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸º`underfitting`ï¼Œè€Œå¦‚æœå›å½’æ›²çº¿é«˜åº¦è´´åˆæ¯ä¸€ä¸ªæ ·æœ¬æ•°æ®ï¼Œå¯¼è‡´æ›²çº¿æ­ªæ­ªæ‰­æ‰­ï¼Œè¿™æ ·è¿‡åº¦è¿åˆäº†æ ·æœ¬æ•°æ®ï¼Œç”šè‡³åŒ…æ‹¬ç‰¹ä¾‹ï¼Œåè€Œéå¸¸ä¸åˆ©äºé¢„æµ‹æœªçŸ¥çš„æ•°æ®ï¼Œè¿™ç§æƒ…å†µå°±æ˜¯`overfitting`ï¼Œè¿‡åº¦æ‹Ÿåˆäº†ï¼Œå®ƒçš„ç¼ºç‚¹å°±ä¸å¤Ÿgeneralize wellã€‚

å¦‚æœæˆ‘ä»¬çš„featureè¿‡å¤šï¼Œè€Œè®­ç»ƒæ ·æœ¬é‡åˆéå¸¸å°ï¼Œ`overfitting`å°±éå¸¸å®¹æ˜“å‘ç”Ÿã€‚

Options:
1. Reduce number of features
    - Manually select which features to keep.
    - Model selection algorithm (later in course).
2. Regularization
    - Keep all the features, but reduce magnitude/values of parameters $\theta_j$.
    - Works well when we have a lot of features, each of which contributes a bit to predicting $y$.

## Regularization

### Cost function

Samll values for parameters $\theta_0, \theta_1, \dots, \theta_n$
 - "Simpler" hypothesis
 - Less prone to overfitting

Housing:
 - Features: $x1, x2, \dots, x100$
 - Parameters:$\theta_0, \theta_1, \dots, \theta_100$

$$
J(\theta) = \frac{1}{2m} \left[
    \sum_{i=1}^m(h_\theta(x^{(i)}) - y^{(i)})^2 
    \overbrace{\red{+ \lambda\sum_{j=1}^n\theta_j^2}}^{\tt \small regulation\ term}
\right]
$$
and $\lambda$ here is `regularization parameter`,  It determines how much the costs of our theta parameters are inflated. 

We've added two extra terms at the end to inflate the cost $\theta_j(1,n)$, Now, in order for the cost function to get close to zero, we will have to reduce the values of $\theta_j$s to near zero.
ä¸€èˆ¬è¿™äº›éƒ½å‘ç”Ÿåœ¨é«˜é˜¶çš„å‚æ•°ä¸Šï¼Œæ¯”å¦‚$\theta_3x^3,\ \theta_4x^4$ï¼Œè¿™äº›å€¼å°†ä¼šå˜å¾—éå¸¸å°ï¼Œè¡¨ç°åœ¨å‡½æ•°æ›²çº¿ä¸Šï¼Œå°†ä¼šå¤§å¤§å‡å°æ›²çº¿çš„æ³¢åŠ¨ã€‚

### Regularized linear regression

æˆ‘ä»¬ä¸å¯¹$\theta_0$åšpenalizeï¼Œè¿™æ ·æ›´æ–°å‡½æ•°å°±å˜æˆäº†ï¼š
$$\begin{aligned}
&\theta_0 := \theta_0 - \alpha\frac{1}{m}\sum_{i=1}^m(h_\theta(x^{(i)}) - y^{(i)})x_0^{(i)} \\
&\theta_j := \theta_j - \alpha\left[
    \left(
        \frac{1}{m}\sum_{i=1}^m(h_\theta(x^{(i)}) - y^{(i)})\cdot x_j^{(i)}
    \right) + \frac{\lambda}{2m}\theta_j^2
\right]\quad\quad j\in\{1,2,\dots,n\} \\
&\theta_j := \theta_j(1-\alpha\frac{1}{m}) - 
\alpha\frac{1}{m} \sum_{i=1}^m(h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)}
\end{aligned}
$$

$1-\alpha\frac{1}{m} < 1$ï¼Œå¯ä»¥ç›´è§‚åœ°ç†è§£ä¸ºå®ƒæ¯è½®éƒ½æŠŠ$\theta_j$å‡å°äº†ä¸€å®šçš„å€¼ã€‚

#### Normal Equation

$$
\theta = (X^TX + \lambda \cdot L)^{-1}X^Ty
$$
$$
\tt where\ L = \begin{bmatrix}
0 &&&&\\
&1&&&\\
&&1&&\\
&&&\ddots&\\
&&&&1
\end{bmatrix}
$$

Recall that if m < n, then $X^TX$ is non-invertible. However, when we add the term Î»â‹…L, then $X^TX+ Î»â‹…L$ becomes invertible.

### Regularized Logistic Regression

#### Feature mapping

One way to fit the data better is to create more features from each data point. æ¯”å¦‚ä¹‹å‰çš„ä¸¤ä¸ªfeatureçš„ä¾‹å­ï¼Œæˆ‘ä»¬å°†å®ƒæ‰©å±•åˆ°6æ¬¡æ–¹ï¼š
$$\tt{mapped\ features}=
\begin{bmatrix}
    1\\x_1\\x_2\\x_1^2\\x_1x_2\\x_x^2\\x_1^3\\\vdots\\x_1x_2^5\\x_2^6
\end{bmatrix}$$

As a result of this mapping, our vector of two features has been transformed into a 28-dimensional vector. A logistic regression classifier trained on this higher-dimension feature vector will have a more complex decision boundary and will appear nonlinear when drawn in our 2-dimensional plot.

æ­¤æ—¶å†ç”»2Då›¾æ—¶ï¼ˆè¡¨ç¤º`decision boundary`ï¼‰ï¼Œå°±å¾—ç”¨ç­‰é«˜çº¿äº†(`contour`)

$$
J(\theta) =\frac{1}{m}\sum_{i=1}^m{\left[-y^{(i)} \log(h_{\theta}(x^{(i)}))-(1-y^{(i)}) \log(1-h_{\theta}(x^{(i)}))\right]}
+\frac{\lambda}{2m}\sum_{j=1}^n{\theta_j^2}
$$

æ±‚å¯¼æ—¶æ³¨æ„ç¬¬1åˆ—xæ˜¯è¡¥çš„1ï¼Œä¹ŸæŠŠ$\theta_0$ç»™æå–å‡ºæ¥ï¼š
$$
\frac{\partial J(\theta)}{\partial \theta_j} = \frac{1}{m}\sum_{i=1}^m\left( h_\theta(x^{(i)})-y^{(i)}\right)x_j^{(i)}\qquad \mathrm{for}\;j=0,
$$
$$
\frac{\partial J(\theta)}{\partial \theta_j} = \left( \frac{1}{m}\sum_{i=1}^m{\left( h_\theta(x^{(i)})-y^{(i)}\right)x_j^{(i)}} \right)+\frac{\lambda}{m}\theta_j\qquad \mathrm{for}\;j\geq1,
$$

# Neural Networks Representation

Logistic regression cannot form more complex hypotheses as it is only a `linear classier`. (You could add more features such as polynomial features to logistic regression, but that can be very expensive to train.) 

The neural network will be able to represent complex models that form non-linear hypotheses. 

## Non-linear hypotheses

éçº¿æ€§å›å½’åœ¨ç‰¹å¾æ•°è¿‡å¤šæ—¶ï¼Œç‰¹åˆ«æ˜¯ä¸ºäº†å……åˆ†æ‹Ÿåˆæ•°æ®ï¼Œéœ€è¦å¯¹ç‰¹å¾è¿›è¡Œç»„åˆï¼ˆå‚è€ƒä¸Šç« `feature mappint`)ï¼Œå°†ä¼šäº§ç”Ÿæ›´å¤šçš„ç‰¹å¾ã€‚

æ¯”å¦‚50x50çš„ç°åº¦å›¾ç‰‡ï¼Œæœ‰2500çš„åƒç´ ï¼Œå³2500ä¸ªç‰¹å¾å€¼ï¼Œå¦‚æœéœ€è¦ä¸¤ä¸¤ç»„åˆ(`Quadratic features`)ï¼Œåˆ™æœ‰$\binom{2}{2500} = \frac{2500\times2499}{2} \approx 3\times10^6$ çº¦300ä¸‡ä¸ªç‰¹å¾ï¼Œå¦‚æœä¸‰ä¸‰ç»„åˆï¼Œå››å››ç»„åˆï¼Œç™¾ç™¾ç»„åˆå‘¢ï¼Ÿ

## Neurons and the grain

pass

## Model representation

![](/assets/images/2021-05-04-01-08-16.png)
ç¥ç»å…ƒï¼ˆ`Neuron`ï¼‰æ˜¯å¤§è„‘ä¸­çš„ç»†èƒã€‚å®ƒçš„`input wires`æ˜¯æ ‘çªï¼ˆ`Dendrite`ï¼‰ï¼Œ`output wires`æ˜¯è½´çªï¼ˆ`Axon`ï¼‰ã€‚

in neural network:  
$a_i^{(j)}$ = "activation" of unit `i` in layer `j`  
$\Theta^{(j)}$ = matrix of weights controlling function mapping from layer`j` to layer `j+1`

å¯¹äºæœ‰ä¸€ä¸ª`hidden layer`çš„ç¥ç»ç½‘ç»œï¼š 
<img src=/assets/images/2021-05-04-01-32-24.png style='float:right; margin-right:100px; width:400px' />
$\begin{aligned}
a_1^{(2)} &= g(\Theta_{10}^{(1)}x_0+\Theta_{11}^{(1)}x_1+\Theta_{12}^{(1)}x_2+\Theta_{13}^{(1)}x_3) \\
a_2^{(2)} &= g(\Theta_{20}^{(1)}x_0+\Theta_{21}^{(1)}x_1+\Theta_{22}^{(1)}x_2+\Theta_{23}^{(1)}x_3) \\
a_3^{(2)} &= g(\Theta_{30}^{(1)}x_0+\Theta_{31}^{(1)}x_1+\Theta_{32}^{(1)}x_2+\Theta_{33}^{(1)}x_3) \\
h_\Theta(x) &= a_1{(3)} \\ &= g(\Theta_{10}^{(2)}a_0^{(2)}+\Theta_{11}^{(2)}a_1^{(2)}+\Theta_{12}^{(2)}a_2^{(2)}+\Theta_{13}^{(2)}a_3^{(2)})
\end{aligned}$

 If layer 1 has 2 input nodes and layer 2 has 4 activation nodes. Dimension of $\Theta^{(1)}$ is going to be 4Ã—3 where $s_j = 2$ and $s_{j+1} = 4$, so $s_{j+1} \times (s_j + 1) = 4 \times 3$

### Forward propagation: Vectorized implementation

ä¸Šé¢çš„ç­‰å¼å…¶å®å·²ç»å¾ˆæ˜ç¡®åœ°è¡¨ç°å‡ºäº†çŸ©é˜µçš„å½¢æ€ï¼Œæˆ‘ä»¬å†ä»¤ï¼š$\Theta^{(i)}_jx_k = z^{(i)}_j$
$
x = \begin{bmatrix}x_0\\x_1\\x_2\\x_3\end{bmatrix} \quad \quad
z^{(2)} = \begin{bmatrix}z^{(2)}_1\\z^{(2)}_2\\z^{(2)}_3\\z^{(2)}_4\end{bmatrix}
$

$z^{(2)} = \Theta^{(1)}x \quad (\rm{for\ uniform,\ set}\ x = a^{(1)}) \to z^{(2)} = \Theta^{(1)}a^{(1)}$
$a^{(2)} = g(z^{(2)})$

Add $a^{(2)}_0 = 1 \to$
$z^{(3)} = \Theta^{(2)}a^{(2)}$
$h_\Theta(x) = a^{(3)} = g(z^{(3)})$

æ¢³ç†ä¸€ä¸‹ï¼š
$\begin{array}{|l|}
\hline\\
\tt generalize: \\ \\
\begin{aligned}
    z^{(j)} &=\Theta^{(jâˆ’1)}a^{(jâˆ’1)} \\
    a^{(j)} &= g(z^{(j)}) \\
    z^{(j+1)} &= \Theta^{(j)}a^{(j)} \\
    h_\Theta(x) &= a^{(j+1)} \\ &= g(z^{(j+1)})\\
\end{aligned} \\
\hline
\end{array}$

### Examples and Intuitions

å‡è®¾$x_1, x_2 \in {0 ,1}$ï¼Œæˆ‘ä»¬å¦‚ä½•ç”¨ç¥ç»ç½‘ç»œæ¥æ¨¡æ‹Ÿ$x_1$ And $x_2$ï¼Ÿ

å…¶å®å°±æ˜¯æ‰¾å‡ºä¸‰ä¸ªå‚æ•°ï¼Œè®©$\theta_0 + \theta_1x_1 + \theta_2x_2$ åœ¨ä¸åŒçš„$x_1, x_2$ç»„åˆé‡Œåˆ†åˆ«å¾—åˆ°é¢„æœŸçš„å€¼ï¼Œæ¯”å¦‚æˆ‘ä»¬è¿™é‡Œæ‰¾åˆ°äº†[-30, 20, 20]ï¼Œä»£å…¥ç®—å¼ï¼Œä»¥åŠå›å¿†`Sigmoid`å‡½æ•°ï¼Œæ±‚è¯ï¼š

$x_1$ | $x_2$ | exp | $y$
------|-------|-----|----
1 | 1 | g(10) | 1
0 | 0 | g(-30) | 0
1 | 0 | g(-10) | 0
0 | 1 | g(-10) | 0
see? exactly A&B
> ç­‰äºç”¨å››ä¸ªè®­ç»ƒæ ·æœ¬æ¥è®­ç»ƒå‡ºåˆé€‚çš„å‚æ•°

è¯•è¯•è‡ªå·±æ±‚åˆ«çš„é€»è¾‘è¿ç®—ç¬¦ï¼Ÿ

ç°åœ¨æˆ‘ä»¬è¦æ±‚$x_1$ XNOR $x_2$ï¼Œè¿™æ˜¯$x_1$ XOR $x_2$çš„è¡¥é›†ï¼Œå¯¹äº**XOR**ï¼Œåªæœ‰åœ¨ä¸¤è€…ä¸åŒæ—¶ä¸ºçœŸæ—¶æ‰ä¸ºçœŸï¼Œé‚£ä¹ˆ**XNOR**ï¼Œæ˜¾ç„¶ä¸ºçœŸæ—¶å°±æ˜¯ä¸¤è€…åŒæ—¶ä¸º0ï¼Œæˆ–ä¸¤è€…åŒæ—¶ä¸º1äº†ã€‚

ç”±ä¸Šä¸€å¥è¯ï¼Œæˆ‘ä»¬æ˜¯å¦å¯ä»¥å¾—åˆ°ä¸‰ä¸ªé€»è¾‘è¿ç®—ç¬¦ï¼Ÿ
1. ä¸¤è€…åŒæ—¶ä¸º0 å³ï¼ˆnot a) **AND** (not b)
2. ä¸¤è€…åŒæ—¶ä¸º1 å³ï¼ˆnot a) **OR** (not b)
3. ä¸Šè¿°ä¸¤è€…ä»»æ„æ»¡è¶³ä¸€ä¸ªå³å¯ï¼Œ1 **OR** 2

æˆ‘ä»¬åˆ™å¯ä»¥æŠŠå‰ä¸¤è€…è¾“å‡ºåˆ°éšå±‚ï¼Œåªä¸“æ³¨ä¸€ä¸ªåˆ¤æ–­ï¼Œåœ¨Output layeræ‰ç»„åˆ1å’Œ2  
åŒæ—¶ï¼Œéšå±‚æˆ‘ä»¬åªå…³å¿ƒå…¨çœŸï¼Œå’Œå…¨å‡ï¼Œè¿™ä¸¤ç§æƒ…å†µï¼Œå› æ­¤åªéœ€è¦ä¸¤ä¸ªèŠ‚ç‚¹ï¼Œæœ€åï¼Œä¸æ–­çš„è®­ç»ƒä¸­ï¼Œæ€»èƒ½è¯•åˆ°å¦‚ä¸‹å›¾çš„å‚æ•°ï¼Œä»è€Œäº§ç”Ÿäº†æ­£ç¡®çš„è¾“å‡ºï¼Œè¿™é‡Œæ¨¡å‹å°±ç®—è®­ç»ƒå®Œæ¯•äº†ã€‚

![](/assets/images/2021-05-05-00-08-40.png)

ç»“è®º1:
> æˆ‘ä»¬å¾—åˆ°äº†ä¸€ä¸ªæ‹†åˆ†ç‰¹å¾ï¼Œç„¶åç”¨æ–°çš„ç‰¹å¾å»å¾—åˆ°è¾“å‡ºçš„ä¾‹å­ã€‚

ç»“è®º2:
> ä½†å¦‚æœå†™æˆä»£ç ï¼Œæˆ‘ä»¬åªä¼šçœ‹å†™äº†ä¸‰å±‚ï¼Œä½†ä¸çŸ¥é“éšå±‚è¾“å‡ºäº†ä»€ä¹ˆï¼Œå› ä¸ºä»£ç `å¹¶æ²¡æœ‰`è®©ç¬¬ä¸€å±‚å»æ‰¾â€œå…¨çœŸï¼Œå…¨å‡â€ï¼Œä½ èƒ½çœ‹åˆ°çš„å°±æ˜¯æƒé‡ç›¸åŠ ï¼Œæ­£å‘ä¼ æ’­ï¼Œç„¶ååå‘ä¼ æ’­ã€‚

ç»“è®º3:
> è¿™é‡Œæœ‰ä¸€ä¸ªå¾ˆé‡è¦çš„ç‚¹ï¼Œå³åˆ†å±‚åšäº†ä»€ä¹ˆäº‹ï¼Œåªæ˜¯ä¸€ä¸ª`æœŸæœ›`ï¼Œå¹¶ä¸æ˜¯ç”¨ä»£ç å»`å¼•å¯¼`å¾—æ¥çš„ã€‚**ä¹Ÿå°±æ˜¯è¯´**ï¼Œå¦‚æœå¾—åˆ°çš„æ¨¡å‹ï¼Œå…¶å®å®ƒçš„å„éšå±‚å…¶å®æ˜¯è¾“å‡ºäº†`åˆ«çš„`ç‰¹å¾ä¸æƒé‡çš„ç»„åˆï¼Œæˆ‘ä»¬ä¹Ÿ**ä¸çŸ¥é“**ï¼Œä»¥åŠï¼Œ**é¿å…ä¸äº†**ï¼

ç»“è®º4:
> ä¹Ÿå°±æ˜¯è¯´ï¼Œåœ¨ç¼–ç¨‹çš„æ—¶å€™ï¼Œæˆ‘ä»¬æ˜ç¡®çŸ¥é“éœ€è¦ä¸€ä¸ªä»€ä¹ˆæ ·çš„æ¨¡å‹ï¼Œä½†ä¸æ˜¯å»â€œ**æŒ‡å¯¼**â€è¿™ä¸ªæ¨¡å‹çš„æ¯ä¸€å±‚å»åšä»€ä¹ˆäº‹ï¼Œåªèƒ½åœ¨æ¢¯åº¦ä¸‹é™ä¸­ï¼ˆä¸ç„¶å°±æ˜¯çº¯ç›²çŒœä¸­ï¼‰`æœŸæœ›`å¾—åˆ°ç¬¦åˆè¿™ä¸ªæ¨¡å‹çš„å‚æ•°ã€‚
> å¯èƒ½æˆ‘ä»¬å”¯ä¸€èƒ½åšçš„ï¼Œå°±æ˜¯æ ¹æ®æˆ‘ä»¬çš„å»ºæ¨¡ï¼Œå»è®¾ç½®ç›¸åº”ä¸ªæ•°çš„`éšå±‚å±‚æ•°`ï¼Œæ¯ä¸€ä¸ªéšå±‚çš„`èŠ‚ç‚¹ä¸ªæ•°`ï¼Œä»¥æœŸæœ€ç»ˆè®­ç»ƒå‡ºçš„æ¨¡å‹æ˜¯ç¬¦åˆæˆ‘ä»¬æœŸå¾…è€Œä¸æ˜¯åˆ«çš„æ¨¡å‹çš„ã€‚

ä»¥ä¸Šæ˜¯ç¥ç»ç½‘ç»œèƒ½åšå¤æ‚çš„äº‹çš„æœ€ç›´è§‚è§£é‡Šä»¥åŠæœ€å®Œæ•´ä¾‹å­äº†ï¼ˆä½ çœŸçš„è®­ç»ƒå‡ºäº†ä¸€ä¸ªæœ‰å®é™…æ„ä¹‰çš„æ¨¡å‹ï¼‰ã€‚

## Multi-class classification

æ¯”å¦‚ä¸€ä¸ªè¯†åˆ«äº¤é€šå·¥å…·çš„è®­ç»ƒï¼Œ**é¦–å…ˆ**ï¼Œå°±æ˜¯è¦æŠŠ$y \in \{1,2,3,4\}$æ”¹ä¸º $y^{(i)}\ one\ of \begin{bmatrix}
1\\0\\0\\0\end{bmatrix}, 
\begin{bmatrix}0\\1\\0\\0\end{bmatrix},\cdots
$
æœ‰äº†å‰é¢çš„è¯¾ç¨‹ï¼Œæƒ³å¿…ä¹ŸçŸ¥é“è¿™æ˜¯ä¸ºäº†å¯¹åº”æ¯ä¸€æ¬¡outputå…¶å®éƒ½ä¼šæœ‰4ä¸ªè¾“å‡ºï¼Œä½†åªæœ‰ä¸€ä¸ªæ˜¯â€œå¯èƒ½æ€§æœ€é«˜â€çš„è¿™æ ·çš„`å½¢çŠ¶`ï¼ˆOne-vs-restï¼‰ï¼Œåœ¨ç¼–ç¨‹å®è·µä¸­ï¼Œä¹Ÿä¼šæŠŠè®­ç»ƒçš„å¯¹ç…§ç»“æœæå‰å˜æˆçŸ¢é‡ã€‚

# Neural Networks: Learning

## Cost function

in Binary classification, y = 0 or 1, has `1` output unit, and $h_\theta(x) \in R^1$

in Multi-class classification, suppose we have `k` classes, the $h_\theta(x) \in R^k$
e.g. k = 4
$
\begin{bmatrix}1\\0\\0\\0\end{bmatrix},
\begin{bmatrix}0\\1\\0\\0\end{bmatrix},
\begin{bmatrix}0\\0\\1\\0\end{bmatrix},
\begin{bmatrix}0\\0\\0\\1\end{bmatrix}
$

$k\ge3$, because if k==2, it can be a `Binary classification`

some symbols:
- L: total number of layers in the network
- $S_l$: number of units (not counting bias unit) in layer `l`
- K: number of output units/classes

recall `logistic regression`:
$$
J(\theta) =-\frac{1}{m}\left[\sum_{i=1}^m{y^{(i)} \log(h_{\theta}(x^{(i)}))+(1-y^{(i)}) \log(1-h_{\theta}(x^{(i)}))}\right]
+\frac{\lambda}{2m}\sum_{j=1}^n{\theta_j^2}
$$
in Neural Network:
$$
h_\Theta(x) \in R^K \quad (h_\Theta(x))_i = i^{th}\ \rm output
$$
$$
\begin{aligned}
J(\Theta) = & -\frac{1}{m}\left[\sum_{i=1}^m\sum_{k=1}^K{y^{(i)}_k \log((h_{\Theta}(x^{(i)}))_k)+(1-y^{(i)}_k) \log(1-(h_{\Theta}(x^{(i)}))_k)}\right]  \\
+&\frac{\lambda}{2m}\sum_{L=1}^{L-1}\sum_{i=1}^{S_l}\sum_{j=1}^{S_{l+1}}{(\Theta_{ij}^{(l)})^2}
\end{aligned}
$$

Note:

- the double sum simply adds up the logistic regression costs calculated for each cell in the output layer
- the triple sum simply adds up the squares of all the individual Î˜s in the entire network.
- the i in the triple sum does not refer to training example i

## Back propagation algorithm(BP)

In order to use either gradient descent or one of the advance optimization algorithms, we need code to compute:
<img src='/assets/images/2021-05-06-01-56-36.png' style='float:right; margin-right:160px; width:350px' />
- $J(\Theta)$ 
- $\frac{\partial}{\partial\Theta_{ij}^{(l)}}J(\Theta)$

Intuition: $\delta_j^{(l)}$ = `error` of node `j` in layer `l`
For each output unit (layer L=4)
$\begin{aligned}
\delta_j^{(4)} &= a_j^{(4)} - y_j \\
               &=(h_\Theta(x))_j - y_j \\
&\underrightarrow{\,\ vectorization\ \,} \\
\delta^{(4)} &= a^{(4)} - y \\
\delta^{(3)} &= (\Theta^{(3)})^T\delta^{(4)}.*g'(z^{(3)}) \\
\delta^{(2)} &= (\Theta^{(2)})^T\delta^{(3)}.*g'(z^{(2)})
\end{aligned}
$

> æ³¨ï¼š
1. ç¬¬`L`å±‚**output layer**å†™æˆ`a-y`æ˜¯é€»è¾‘å›å½’çš„`cost function`çš„å¯¼æ•°çš„æ¨å¯¼åçš„ç»“æœ
2. æ‰€ä»¥å…¶å®å®ƒçš„å…¬å¼è·Ÿå…¶å®ƒéšå±‚éƒ½æ˜¯ä¸€æ ·çš„ï¼Œå³ä¸Šå±‚çš„å¯¼æ•° * æœ¬å±‚`æ¿€æ´»å‡½æ•°`çš„å¯¼æ•°
3. å¦‚æœ`g`æ˜¯`sigmoid`ï¼Œé‚£ä¹ˆ$g'(z^{(3)}) = a^{(3)} .* (1 - a^{(3)})$

`back propagation`æŒ‡çš„å°±æ˜¯è¿™ä¸ª$\delta$ç”±åå‘å‰ä¼ æ’­çš„è¿‡ç¨‹ã€‚

$\frac{\partial}{\partial\Theta_{ij}^{(l)}}J(\Theta) = 
a_j^{(l)}\delta_j^{(l+1)}$ ignoring $\lambda$ if $\lambda = 0$ ï¼ˆæ— è¯æ˜æ­¥éª¤ï¼‰

å®Œæ•´è¿‡ç¨‹ï¼Œfor training set: $\{(x_{(1)}, y_{(1)}),(x_{(2)}, y_{(2)}),\dots,(x_{(m)}, y_{(m)})\}$

set $\Delta_{ij}^{(l)} = 0$ (for all l, i, j)

For i = 1 to m:
- Set $a^{(1)} := x^{(i)}$ (hence you end up having a matrix full of zeros)
- perform forward propagation to compute $a^{(l)}$ for l = 2, 3, ..., L
- Using $y^{(i)}$, compute $\delta^{(L)} = a^{(L)} - y^{(i)}$
- Compute $\delta^{(L-1)}, \delta^{(L-2)},\dots,\delta^{(2)} \quad \red{\cancel{\delta^{(1)}}}$ using: $\delta^{(l)} = (\Theta^{(l)})^T\delta^{(l+1)} .* a^{(l)} .* (1 - a^{(l)})$
- $\Delta_{ij}^{(l)} := \Delta_{ij}^{(l)} + a_j^{(l)}\delta_i^{(l+1)} \Rightarrow
\Delta^{(l)} := \Delta^{(l)} + \delta^{(l+1)}(a^{(l)})^T
$

æœ€åï¼š
$
\frac{\partial}{\partial\Theta_{ij}^{(l)}}J(\Theta) = 
\begin{cases}
    D_{ij}^{(l)} := \frac{1}{m}\Delta_{ij}^{(l)} &if\;\ j = 0 \\[2ex]
    D_{ij}^{(l)} := \frac{1}{m}\Delta_{ij}^{(l)} +\frac{\lambda}{m}\Theta_{ij}^{(l)} \quad &if\;\ j\ne 0
\end{cases}$

è®°ä½ï¼Œ $\delta_j^{(l)}$ is the `error` of cost for $a_j^{(l)}$ï¼Œå³ $\frac{\partial}{\partial z_j^{(l)}}cost(i)$

how to calculate $\delta$:
![](/assets/images/2021-05-13-02-18-48.png)

## Uniforming parameters

è¦ä½¿ç”¨`fminunc()`ï¼Œæˆ‘ä»¬è¦æŠŠæ‰€æœ‰å‚æ•°æ‹å¹³é€è¿›å»ï¼š
```
thetaVector = [ Theta1(:); Theta2(:); Theta3(:); ]
deltaVector = [ D1(:); D2(:); D3(:) ]
```
è®°ä½`(:)`æ˜¯å–å‡ºæ‰€æœ‰å…ƒç´ ï¼Œå¹¶ç«–å‘æ’åˆ—

å¯¹äº10x11, 10x11, 1x11çš„ä¸‰ä¸ªthetaï¼Œåœ¨æ‹å¹³åæˆ‘ä»¬è¦è¿˜åŸçš„è¯ï¼š
```
Theta1 = reshape(thetaVector(1:110),10,11)
Theta2 = reshape(thetaVector(111:220),10,11)
Theta3 = reshape(thetaVector(221:231),1,11)
```
æ‰€ä»¥ï¼Œ octaveaæˆ–matlabçš„åˆ‡ç‰‡æ˜¯åŒ…å¤´åŒ…å°¾çš„

![](/assets/images/2021-05-13-02-41-35.png)

## Gradient checking

å› ä¸ºBPæ˜¯å¦‚æ­¤å¤æ‚åˆé»‘ç›’ï¼Œä½ å¾€å¾€ä¸çŸ¥é“è‡ªå·±åœ¨å±‚å±‚æ±‚å¯¼çš„è¿‡ç¨‹ä¸­æ¯ä¸€æ­¥åˆ°åº•æ˜¯ä¸æ˜¯å¯¹çš„ï¼Œå› ä¸ºæˆ‘ä»¬å¼•å…¥äº†æ£€æŸ¥æœºåˆ¶ï¼Œç”¨éå¸¸å¾®å°çš„yå˜åŠ¨é™¤ä»¥ç›¸åº”éå¸¸å¾®å°çš„xå˜åŠ¨æ¥æ¨¡æ‹Ÿä¸€ä¸ª`å¯¼æ•°`ï¼Œä¸€èˆ¬å–$10^{-4}$ã€‚
$$
\frac{\partial}{\partial\theta_j}J(\Theta) = 
\frac{J(\Theta_1,\dots,\Theta_{j-\epsilon},\dots,\Theta_n) - J(\Theta_1,\dots,\Theta_{j+\epsilon},\dots,\Theta_n)}
{2\epsilon}
$$
å¦‚ä¸Šæ¯ä¸€ä¸ªå‚æ•°éƒ½æ£€æŸ¥ä¸€æ¬¡ï¼Œå¦‚æœç»“æœç›¸å½“è¿‘ä¼¼ï¼Œè¯´æ˜ä½ çš„ä»£ç æ˜¯æœ‰ç”¨çš„ï¼Œåœ¨è®­ç»ƒå‰ä¸€å®šè¦è®°å¾—å…³æ‰Gradient checking.

```
epsilon = 1e-4;
for i = 1:n,
  thetaPlus = theta;
  thetaPlus(i) += epsilon;
  thetaMinus = theta;
  thetaMinus(i) -= epsilon;
  gradApprox(i) = (J(thetaPlus) - J(thetaMinus))/(2*epsilon)
end;
```

## Random initialization

Initializing all theta weights to zero does not work with neural networks. When we backpropagate, all nodes will update to the same value repeatedly. Instead we initialize each $\Theta_{ij}^{(l)}$ to a random value in $[-\epsilon, \epsilon]$

## put together

make sure:
1. number of input units (aka `features`)
2. number of output units (aka `classes`)
3. number of hidden layers and units per layer (defaults: 1 hidden layer)

Training a Neural Network
1. randomly initialize the weights
2. implement `forward propagation` to get $h_\Theta(x^i)$ for any $x^i$
3. implement the cost function
4. implement `backward propagation` to compute partial derivatives
5. use gradient checking to confirm that your BP works, then **disable** gradient checking
6. use gradient descent or a built-in optimazation function to minimize the cost function with the weights in theta.

# Advice for applying machine learning

ä¸ºäº†è®©ç²¾åº¦æ›´é«˜ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šç›²ç›®é‡‡å–å¦‚ä¸‹åšæ³•ï¼š
- get more training examples
- try smaller sets of features
- try getting additional features
- try adding polynomial features ($x^2_1, x^2_2, x_1x_2, etc.$)
- try decreasing / increasing $\lambda$

æœ€ç»ˆï¼Œæœ‰æ•ˆçš„testæ‰èƒ½ä¿è¯ä½ è¿›è¡Œæœ€æœ‰æ•ˆçš„æ”¹è¿›ï¼šMachine Learning diagnostic

## Evaluating a hypothesis

æ‹¿ä¸€éƒ¨åˆ†è®­ç»ƒæ•°æ®å‡ºæ¥åšæµ‹è¯•æ•°æ®(70%, 30%)ï¼Œæœ€å¥½å…ˆæ‰“ä¹±ã€‚(Training Set, Test Set)

å¯¹äºçº¿æ€§å›å½’é—®é¢˜ï¼Œå°†è®­ç»ƒé›†çš„å‚æ•°åº”ç”¨åˆ°æµ‹è¯•é›†ï¼Œç›´æ¥è®¡ç®—å‡ºæµ‹è¯•é›†çš„è¯¯å·®å³å¯ï¼š
$J_{test}\Theta = \frac{1}{2m_{test}}\sum_{i=1}^{m_{test}}(h_\Theta(x^{(i)}_{test} - y^{(i)}_{test}
))^2$
å¯¹äºé€»è¾‘å›å½’ï¼Œåº”ç”¨`0/1 misclassification error`(é”™åˆ†ç‡)
$
err(h_\Theta(x), y) = \begin{cases}
1 & if\ h_\Theta(x) \ge 0.5\ and\ y=0 \\
  & \quad or \\
  & h_\Theta(x) \lt 0.5\  y=1 \\
0 & otherwise
\end{cases}
$
$Test\ Error = \frac{1}{m_{test}}\sum^{m_{test}}_{i=1}err$

## Model selection and training/validation/test sets

åœ¨æµ‹è¯•é›†ä¸Šè°ƒè¯•$\Theta$ä»ç„¶å¯èƒ½äº§ç”Ÿè¿‡æ‹Ÿåˆï¼Œç”±æ­¤ç»§ç»­å¼•å…¥ä¸€ä¸ª`Cross Valication Set`ï¼Œè¿™æ¬¡ç”¨60%, 20%, 20%æ¥åˆ†äº†ï¼ŒåŸç†ä¹Ÿå¾ˆç›¸äº’ï¼Œå°±æ˜¯ä»ç„¶åœ¨æ¯ä¸ªé›†é‡Œæ‰¾åˆ°æœ€å°çš„$J(\Theta)$ï¼Œä½†æ˜¯ç”¨`CV`é›†é‡Œçš„æ¨¡å‹å»æµ‹è¯•é›†é‡Œé¢„æµ‹ã€‚

æ­¥éª¤æ˜¯ï¼š
1. åœ¨**æµ‹è¯•é›†**é‡Œå¯¹æ¯ä¸ªæ¨¡å‹è¿›è¡Œ$\Theta$çš„ä¼˜åŒ–ï¼Œå¾—åˆ°å…¶æœ€å°å€¼
2. åˆ©ç”¨1çš„$\Theta$åœ¨**äº¤å‰éªŒè¯é›†**é‡Œæ‰¾åˆ°è¯¯å·®æœ€å°çš„æ¨¡å‹
3. ç”¨ä¸Šä¸¤æ­¥å¾—åˆ°çš„$\Theta$å’Œæ¨¡å‹ï¼Œè®¡ç®—æ³›åŒ–çš„error

ç­‰äºåœ¨1ï¼Œ2é‡Œï¼Œæ¯ä¸€æ¡æ•°æ®éƒ½è¿›è¡Œè¿‡äº†Nç§æ¨¡å‹çš„è®¡ç®—ï¼Œå¦‚æœç¡®å®æ¨¡å‹æœ‰æ•ˆï¼Œåœ¨è®­ç»ƒé›†é‡Œä¼˜åŒ–å‡ºæ¥çš„æ¨¡å‹å¾ˆå¯èƒ½ä¸äº¤å‰éªŒè¯é›†é‡Œä¼˜åŒ–å‡ºæ¥çš„æ¨¡å‹æ˜¯ä¸€è‡´çš„ã€‚ä½†ä¸ç®¡ä¸€ä¸ä¸€è‡´ï¼Œè®­ç»ƒé›†åªæä¾›å‚æ•°ï¼Œå‰éªŒé›†æä¾›æ¨¡å‹ï¼Œæœ€åæµ‹è¯•é›†æä¾›æ•°æ®(X), æ¥ç®—error